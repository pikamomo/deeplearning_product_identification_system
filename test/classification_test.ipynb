{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-22T19:31:50.435082Z",
     "start_time": "2025-09-22T19:31:50.431070Z"
    }
   },
   "source": [
    "classification_names = {\n",
    "    0: 'cloth',\n",
    "    1: 'shoe',\n",
    "    2: 'bag',\n",
    "    3: 'pants',\n",
    "    4: 'watch'\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:35:53.321758Z",
     "start_time": "2025-09-22T19:35:52.947178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n"
   ],
   "id": "869f6376e68917da",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:46:06.582457Z",
     "start_time": "2025-09-22T19:46:06.577455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sorted_alphanum(img_names):\n",
    "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
    "    alphanum_key = lambda img_name: [convert(x) for x in re.split(r'([0-9]+)', img_name)]\n",
    "    return sorted(img_names, key=alphanum_key)\n",
    "\n",
    "class ImageLabelDataSet(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        super(ImageLabelDataSet, self).__init__()\n",
    "        self.main_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_names = sorted_alphanum(os.listdir(self.main_dir))\n",
    "        self.labels = pd.read_csv(\"../common/fashion-labels.csv\")\n",
    "        self.label_dict = dict(zip(self.labels['id'], self.labels['target']))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_loc = os.path.join(self.main_dir, self.image_names[idx])\n",
    "        image = Image.open(image_loc).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            tenser_img = self.transform(image)\n",
    "        else:\n",
    "            raise ValueError(\"transform is not defined\")\n",
    "\n",
    "        label = self.label_dict[idx]\n",
    "        return tenser_img, label"
   ],
   "id": "6c830a233bf2aa11",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:46:07.279789Z",
     "start_time": "2025-09-22T19:46:07.087739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = T.Compose([\n",
    "    T.Resize((64, 64)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "full_dataset = ImageLabelDataSet(image_dir=\"../common/dataset/\", transform=transform)\n",
    "\n",
    "print(len(full_dataset))"
   ],
   "id": "1d79f824b1622246",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24853\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:46:27.624682Z",
     "start_time": "2025-09-22T19:46:27.619416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import random_split\n",
    "train_set, test_set = random_split(full_dataset, [0.75, 0.25])"
   ],
   "id": "af94f39f7af67d51",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:46:51.936096Z",
     "start_time": "2025-09-22T19:46:51.933353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_set,\n",
    "    batch_size=batch_size\n",
    ")"
   ],
   "id": "52860d61360d1cdd",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:53:37.986525Z",
     "start_time": "2025-09-22T19:53:37.982227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.linear = nn.Linear(in_features=16 * 16 * 16, out_features=5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ],
   "id": "d9fe77a4e7eed58e",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:53:53.426015Z",
     "start_time": "2025-09-22T19:53:53.421902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Classifier()\n",
    "print(model)"
   ],
   "id": "78c723b2accda678",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (linear): Linear(in_features=4096, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:55:30.349999Z",
     "start_time": "2025-09-22T19:55:30.322780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)"
   ],
   "id": "30c94748ee04e3ff",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T19:56:13.263382Z",
     "start_time": "2025-09-22T19:56:13.255845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output = model(images)\n",
    "print(output.shape)"
   ],
   "id": "770347d331c83fb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 5])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "444d585162cf5e9b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
